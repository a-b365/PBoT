{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D-fbgBehLbX"
      },
      "source": [
        "## LLamaIndex is the framwork for Context-Augemented LLM Applications.\n",
        "\n",
        "LLamaIndex imposes no restriction on how you use LLMs. You can use LLMs as auto-complete chatbots, agents, and more. It provides tools like:\n",
        "\n",
        "\n",
        "\n",
        "*   Data connectors ingest your existing data from your existing data from their native source and format. These could be APIs, PDFs, SQL, and (much) more.\n",
        "*   Data indexes structure your data in intermediate representations that are easy and performant for LLMs to consume.\n",
        "*   Engines provide natural language access to your data. Query engines are powerful interfaces for question-answering (e.g. a RAG flow) and Chat engines are conversational messages for multi-message, \"back and forth\" interactions with your data.\n",
        "*   Agents are LLM-powered knowledge workers augemented by tools, from simple helper functions to API integrations and more.\n",
        "*   Observability/Evaluation integrations that enable you to rigourously experiment, evaluate, and monitor your app in a virtuous cycle.\n",
        "*   Workflows allow you to combine all of the above into an event-driven system for flexible than other, graph-based approaches.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkGRGYlZaqyr",
        "outputId": "1783e946-334f-4020-e3c9-d0c6260f5a20"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2RE1A-tbY8_"
      },
      "source": [
        "Context Augmentation makes your data available to the LLM to solve the problem at hand. LlamaIndex provides the tools to build any of the context-augmentation use case, from prototype to production. These tools provide you to ingest, parse, index and process your data and quickly implement complex query workflows combining data access with LLM prompting.\n",
        "\n",
        "The most popular example of context-augmentation is Retrieval-Augmented Generation or RAG, which combines context with LLMs at inference time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_a8KvgQeQBO"
      },
      "source": [
        "Agents are LLM-powered knowledge assistants that use tools to perform tasks like research, data extraction, and more. Agents range from simple question-answering to being able to sense, decide and take actions in order to complete tasks. LlamaIndex provides a framework for building agents including the ability to use RAG pipelines as one of many tools to complete a task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwWB99B9ayh-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMGIO9argl2q"
      },
      "source": [
        "Workflows are multip-step processes that combine one or more agents, data connectors and other tools to complete a task. They are event driven software that allows you to combine a RAG data sources an multiple agents to create a complex application that can perform a wide variety of tasks with reflection, error-correction, and other hallmarks of advanced LLM applications.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU4bgDCplyaj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOZgOvb8n3ZK"
      },
      "source": [
        "Since we get rate limit error everytime we use OpenAI closed source models, we switch to open source models such as gemini, llama2 etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n8JMJTf-WK-y"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-llms-gemini --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3VBnThguDtM",
        "outputId": "752d3598-3f49-443d-b98d-feb51e91e119"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-multi-modal-llms-gemini --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CBMqHR8WmheC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "GOOGLE_API_KEY = \"AIzaSyAHuQtUbzh5DhUm_aNAwX1JC5M0DczVTmY\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "DCloNjFXtYrq",
        "outputId": "88572660-d50a-4957-b013-8ae3ed064037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.gemini import Gemini\n",
        "resp = Gemini().complete(\"Andie Murphy,\")\n",
        "print(type(resp.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "NY6CTKIBNZuo",
        "outputId": "f4d2dc5a-2be3-4f9d-91ed-d813e39dc1b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: Ahoy there! To help me suggest the perfect dinner, tell me a bit about what you're in the mood for:\n",
            "\n",
            "* **What kind of cuisine are you craving?** (Italian, Mexican, Asian, etc.)\n",
            "* **What ingredients do you have on hand?** (Any leftovers, fresh produce, etc.)\n",
            "* **How much time do you have to cook?** (Quick and easy or something more elaborate?)\n",
            "* **Are there any dietary restrictions?** (Vegetarian, vegan, gluten-free, etc.)\n",
            "\n",
            "Once I have a better idea of your preferences, I can suggest some delicious dinner options! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "messages = [\n",
        "\n",
        "        ChatMessage(role=\"user\", content=\"Hello friend!\"),\n",
        "        ChatMessage(role=\"assistant\", content=\"Yarr what is shakin' matey?\"),\n",
        "        ChatMessage(role=\"user\", content=\"Help me decide what to have for dinner.\")\n",
        "\n",
        "]\n",
        "\n",
        "resp = Gemini().chat(messages)\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "BowORbNuX6Kr",
        "outputId": "1c3d531a-3ea1-4a9e-aa52-784a9474bfe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It's great that you're a fan of Star Wars! It's a beloved franchise with a huge impact on popular culture. \n",
            "\n",
            "While many people agree that Star Wars is a fantastic sci-fi movie, it's important to remember that \"greatest\" is subjective. Different people have different tastes and preferences. There are many other incredible sci-fi movies out there, each with its own unique strengths and appeal. \n",
            "\n",
            "It's also important to acknowledge that George Lucas, while a visionary filmmaker, is not the only talented person involved in the Star Wars universe. The success of the franchise is a result of the contributions of countless actors, writers, directors, designers, and other creative individuals. \n",
            "\n",
            "Ultimately, the best way to appreciate the vast world of sci-fi is to explore different movies and find the ones that resonate with you the most. \n",
            "\n",
            "Would you like to discuss some other great sci-fi movies or explore different aspects of the Star Wars universe? \n"
          ]
        }
      ],
      "source": [
        "llm = Gemini()\n",
        "resp = llm.stream_complete(\"Star Wars is the greatest sci-fi movie of all time. George Lucas is the best...\")\n",
        "for r in resp:\n",
        "    print(r.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "-UEhD5ihY-qD",
        "outputId": "869dadba-211a-42b1-dce7-84cb69353f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0827\n"
          ]
        }
      ],
      "source": [
        "#Using other gemini models\n",
        "import google.generativeai as genai\n",
        "\n",
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "aHgWl04kZbDU",
        "outputId": "f4694f45-167c-42e8-99ce-fc00ce6a3f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Star Wars is a popular and influential science fiction franchise created by George Lucas. The first film in the series, Star Wars: Episode IV – A New Hope, was released in 1977 and became a worldwide phenomenon. The franchise has since spawned numerous sequels, prequels, spin-offs, and other media.\n",
            "\n",
            "Whether or not Star Wars is the greatest sci-fi movie of all time is a matter of opinion. There are many other great sci-fi movies out there, such as 2001: A Space Odyssey, Blade Runner, and The Matrix. Ultimately, it is up to each individual to decide which sci-fi movie they enjoy the most.\n",
            "\n",
            "George Lucas is a talented filmmaker who has created some of the most iconic and beloved films in history. However, it is important to remember that he is just one of many talented filmmakers who have contributed to the sci-fi genre. There are many other great sci-fi filmmakers out there, such as Steven Spielberg, Ridley Scott, and James Cameron.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.gemini import Gemini\n",
        "llm = Gemini(model=\"models/gemini-pro\")\n",
        "resp = llm.complete(\"Star Wars is the greatest sci-fi movie of all time. George Lucas is the best...\")\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "ta1L5QqPZnp2",
        "outputId": "f4a6ec90-89bb-45be-c902-4d04211e6cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It's great that you're a fan of Star Wars! It's a beloved franchise with a huge impact on popular culture. \n",
            "\n",
            "While many people agree that Star Wars is a fantastic sci-fi movie, it's important to remember that \"greatest\" is subjective. Different people have different tastes and preferences. There are many other incredible sci-fi movies out there, each with its own unique strengths and appeal. \n",
            "\n",
            "It's also important to acknowledge that George Lucas, while a visionary filmmaker, is not the only talented person involved in the Star Wars universe. The success of the franchise is a result of the contributions of countless actors, writers, directors, artists, and crew members. \n",
            "\n",
            "Ultimately, the best way to appreciate the vast world of sci-fi is to explore different films and find the ones that resonate with you the most. \n",
            "\n",
            "Would you like to discuss some other great sci-fi movies or explore different aspects of the Star Wars universe? \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.gemini import Gemini\n",
        "llm = Gemini()\n",
        "resp = await llm.acomplete(\"Star Wars is the greatest sci-fi movie of all time. George Lucas is the best...\")\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ltUFIv32aNLg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "#Using HuggingFace LLMs\n",
        "\n",
        "%pip install llama-index-llms-huggingface --quiet\n",
        "%pip install llama-index-llms-huggingface-api --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lAD7dr1dn6v"
      },
      "outputs": [],
      "source": [
        "#search instruct model, recommend model etc. to know more about them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8-AdULXePPg",
        "outputId": "c2f6c967-38c2-47ab-bb65-1ad510a841fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/861.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/861.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m860.2/861.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m861.9/861.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install \"transformers[torch]\" \"huggingface_hub[inference]\" --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T79Ekl5HbB5B"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\PBoT\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "d:\\PBoT\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "d:\\PBoT\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "d:\\PBoT\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "d:\\PBoT\\.venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import List, Optional\n",
        "\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "HF_TOKEN:Optional[str] = os.environ.get(\"HF_TOKEN\")\n",
        "# locally_run = HuggingFaceLLM(model_name=\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "remotely_run = HuggingFaceInferenceAPI(model_name=\"HuggingFaceH4/zephyr-7b-alpha\", token=HF_TOKEN)\n",
        "# remotely_run_recommend = HuggingFaceInferenceAPI(token=HF_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY3M5GKRfMQD",
        "outputId": "e435c3f9-dc41-42f0-f9d2-b52e184ec131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ", the most decorated American soldier of World War II, was born in Hunt County, Texas, on June 20, 1924. He was the son of poor tenant farmers, and his family moved frequently during his childhood. Murphy attended school sporadically and left home at age 16 to work as a ranch hand.\n",
            "\n",
            "In 1942, Murphy joined the U.S. Army and was sent to North Africa with the 1st Infantry Division. He fought in the battles of Kasserine Pass and Tunisia, where he was wounded and received his first Purple Heart. Murphy was then sent to Italy, where he fought in the battles of Monte Cassino and Anzio.\n",
            "\n",
            "In January 1944, Murphy was promoted to sergeant and given command of a platoon. He led his men in the brutal fighting at the Colle Chisiolo, where he was wounded again and received his second Purple Heart. Murphy was then sent to France, where he fought in the battles of Normandy and the Ardennes.\n",
            "\n",
            "In January 1945, Murphy was promoted to second lieutenant and given command of Company B, 15th\n"
          ]
        }
      ],
      "source": [
        "completion_response = remotely_run.complete(\"Audie Murphy\")\n",
        "print(completion_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
